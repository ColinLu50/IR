# Midterm Exam

#### Name:      Lu Ning (卢宁)

#### Student Number ：  11610310



## Problem 1

1. D
2. B
3. C
4. B
5. D
6. D
7. A
8. A
9. B
10. C

## Problem 2

### 2.1

(1)  0.78    0.8

![2_1](D:\new_work_space\OS\midterm\pictures\2_1.jpg)

(2)  0.044

![2_1_2](D:\new_work_space\OS\midterm\pictures\2_1_2.jpg)



#### 2.2

![2_2](D:\new_work_space\OS\midterm\pictures\2_2.jpg)



## Problem 3

### 3.1

#### Velocity Mode:

![3_1_vel](D:\new_work_space\OS\midterm\pictures\3_1_vel.jpg)



#### Odometry Model

![3_1_odo](D:\new_work_space\OS\midterm\pictures\3_1_odo.jpg)

#### Similarities

- They both use prob functions to estimate the actual noise.
- They both use the multiply of several probability to estimate the prior probability.
- The pose of robot is expressed in [x y theta]
- They both need parameters to calculate the uncertainty.

#### Differences

- They use different action vector. u = [v w] & u = $[x_t x_{t-1}]$ 



### 3.2

The function **sample**(b~2~) generates a random sample from a zero-centered
distribution with variance b~2~

#### Velocity

![3_2_ve](D:\new_work_space\OS\midterm\pictures\3_2_ve.jpg)

#### Odometry

![3_2_odo](D:\new_work_space\OS\midterm\pictures\3_2_odo.jpg)

#### Similarities

- They both use sample functions to estimate the actual noise.
- They both need parameters for the variance.


#### Differences

- They use different action vector. u = [v w] & u = $[x_t x_{t-1}]$ 
- Factors influenced by the noise are different.



## Problem 4

### 4.1

#### Beam-based 

- Measurement Noise
  $$
  P _ { h i t } ( z | x , m ) = \eta \frac { 1 } { \sqrt { 2 \pi b } } e ^ { - \frac { 1 \left( z - z _ { \mathrm { cq } } \right) ^ { 2 } } { b } }
  $$

- Unexpected Obstacles
  $$
  P _ { \text { unexp } } ( z | x , m ) = \left\{ \begin{array} { c c } { \eta \lambda \mathrm { e } ^ { - \lambda z } } & { z < z _ { \mathrm { exp } } } \\ { 0 } & { \text { otherwise } } \end{array} \right.
  $$

- Random Mesurement
  $$
  P _ { r a n d } ( z | x , m ) = \eta \frac { 1 } { z _ { \max } }
  $$

- Max range
  $$
  P _ { \max } ( z | x , m ) = \eta \frac { 1 } { z _ { \text {small} } }
  $$

$$
P ( z | x , m ) = \left( \begin{array} { c } { \alpha _ { \mathrm { hit } } } \\ { \alpha _ { \mathrm { unexp } } } \\ { \alpha _ { \max } } \\ { \alpha _ { \mathrm { rand } } } \end{array} \right) ^ { T } \cdot \left( \begin{array} { c } { P _ { \mathrm { hit } } ( z | x , m ) } \\ { P _ { \mathrm { unexp } } ( z | x , m ) } \\ { P _ { \max } ( z | x , m ) } \\ { P _ { \mathrm { rand } } ( z | x , m ) } \end{array} \right)
$$




#### Scan-based
- a Gaussian distribution with mean at distance to closest obstacle
- a uniform distribution for random measurements
- a small uniform distribution for max range measurements.

#### Relation

They share some same distribution like **random measurement** and **max range** , and the distributions are combined linearly.

### 4.2

#### generate samples

$$
\begin{aligned}

& \hat { \gamma } = \operatorname { rand } ( 0,2 \pi ) \\
& \hat { r } = r _ { t } ^ { i } + \operatorname { sample } \left( \sigma _ { r } \right) \\
& \hat { \phi } = \phi _ { t } ^ { i } + \text { sample } \left( \sigma _ { \phi } \right) \\
& x = m _ { j , x } + \hat { r } \cos \hat { \gamma } \\
& y = m _ { j , y } + \hat { r } \sin \hat { \gamma } \\
& \\
& m_{j} \text{ is the j-th landmark} \\
& (x,y) \text{is the generated sample}
\end{aligned}
$$



#### caculate


$$
\begin{array} { l } 
{ j = c _ { t } ^ { i } } \\ 
{ \hat { r } = \sqrt { \left( m _ { j , x } - x \right) ^ { 2 } + \left( m _ { j , y } - y \right) ^ { 2 } } } \\ 
{ \hat { \phi } = \operatorname { atan } 2 \left( m _ { j , y } - y , m _ { j , x } - x \right) } \\ 
{ p_{det} = \operatorname { prob } \left( r _ { t } ^ { i } - \hat { r } , \sigma _ { r } \right) \cdot \operatorname { prob } \left( \phi _ { t } ^ { i } - \hat { \phi } , \sigma _ { \phi } \right) } \\
q = z_{det}p_{det} + z_{fp} P _ { \text { uniform } } ( z | x , m )


\end{array}
$$

$$
\begin{array} { l }  
c^i_t = j \text{ means at time t, the i-th feauter corresponds to j-th landmark } \\ 
{ \text { observed feature } f _ { t } ^ { i } = \left( r _ { t } ^ { i } \quad \phi _ { t } ^ { i } \quad s _ { t } ^ { i } \right) ^ { T } \\
\text { the true identity of the feature } c _ { t } ^ { i } \\ \text { the robot pose } x _ { t } = ( x\quad y\quad  \theta ) ^ { T } \\
\text { and the map } m } \\ 
\end{array}
$$





## Problem 5

### 5.1

$$
x _ { \mathrm { t } + 1 } = \mathrm { A } x _ { t } + u _ { t } + w \\
x _ { t } \sim G \left( \mu _ { t } , \Sigma _ { t } \right), w \sim G ( 0 , \mathrm { R } ) \\
{ \mu } _ { t+1 } = A \mu _ { t } + u _ { t } \\
{ \Sigma } _ { t + 1 } = A  \Sigma _ { t } A  ^ { T } + R \\
\overline x _ { t + 1} \sim G \left( \mu _ { t + 1 } , \Sigma _ { t + 1 } \right)
$$

### 5.2

$$
z = C x - m + v \\
C x = (m + z) - v \\
(C ^ {T} Q ^ {-1} C) x = (C ^ {T} Q ^ {-1}) (m + z) - (C ^ {T} Q ^ {-1}) v \\
x = (C ^ {T} Q ^ {-1} C) ^ {-1} (C ^ {T} Q ^ {-1}) (m + z) - (C ^ {T} Q ^ {-1} C) (C ^ {T} Q ^ {-1}) v \\
\text{let } \overline C = (C ^ {T} Q ^ {-1} C) ^ {-1} (C ^ {T} Q ^ {-1}) \\
x = \overline C (m + z) - \overline Cv \\
\mu = \overline C (m+z) = (C ^ {T} Q ^ {-1} C) ^ {-1} (C ^ {T} Q ^ {-1}), \quad
\Sigma = \overline C Q \overline C ^ T = ( C ^ T Q ^ {-1} C ) ^ {-1}
$$



### 5.3

$$
\begin{aligned}
& x _ { t - 1 } \sim G  \left( \mu _ { t - 1} , \Sigma _ { t - 1 } \right) \\
& \overline { \mu } _ { t } = A\mu _ { t - 1 } + u _ { t } \\
& \overline { \Sigma } _ { t } = A \Sigma _ { t - 1 } A ^ { T } + R \\

& p(z_{t}|x_{t}) \sim G \left( C \overline \mu _ { t } - m, C \Sigma _ { t } C ^ T  + Q \right) \\ 

& K _ { t } = \overline { \Sigma } _ { t } C ^ { T } \left( C \overline { \Sigma } _ { t } C ^ { T } + Q \right) ^ { - 1 } \\

& \mu _ { t } = \overline { \mu } _ { t } + K _ { t } \left( z _ { t } - C \overline { \mu } _ { t }  + m\right) \\

& \Sigma _ { t } = \left( I - K _ { t } C \right) \overline { \Sigma } _ { t } \\

& \hat x \sim G \left( \mu _ { t }, \Sigma _ { t }  \right)
\end{aligned}
$$



## Problem 6

### 6.1

$$
\begin{aligned}
p \left( m _ { i } | z _ { 1 : t } , x _ { 1 : t } \right) & = \frac { p \left( z _ { t } | m _ { i } , t - 1 , x _ { 1 : t } \right) p \left( m _ { i } | z _ { 1 : t - 1 } , x _ { 1 : t } \right) } { p \left( z _ { t } | z _ { 1 : t - 1 } , x _ { 1 : t } \right) } \\
& = \frac { p \left( z _ { t } | m _ { i } , x _ { t } \right) p \left( m _ { i } | z _ { 1 : t - 1 } , x _ { 1 : t - 1 } \right) } { p \left( z _ { t } | z _ { 1 : t - 1 } , x _ { 1 : t } \right) } \\
& = \frac { p \left( m _ { i } | z _ { t } , x _ { t } \right) p \left( z _ { t } | x _ { t } \right) p \left( m _ { i } | z _ { 1 : t - 1 } , x _ { 1 : t - 1 } \right) } { p \left( m _ { i } | x _ { t } \right) p \left( z _ { t } | z _ { 1 : t - 1 } , x _ { 1 : t } \right) }\\
& = \frac { p \left( m _ { i } | z _ { t } , x _ { t } \right) p \left( z _ { t } | x _ { t } \right) p \left( m _ { i } | z _ { 1 : t - 1 } , x _ { 1 : t - 1 } \right) } { p \left( m _ { i } \right) p \left( z _ { t } | z _ { 1 : t - 1 } , x _ { 1 : t } \right) } \\
\text{for the opposite event} &  \\
p \left( \neg m _ { i } | z _ { 1 : t } , x _ { 1 : t } \right) & = \frac { p \left( \neg m _ { i } | z _ { t } , x _ { t } \right) p \left( z _ { t } | x _ { t } \right) p \left( \neg m _ { i } | z _ { 1 : t - 1 } , x _ { 1 : t - 1 } \right) } { p \left( \neg m _ { i } \right) p \left( z _ { t } | z _ { 1 : t - 1 } , x _ { 1 : t } \right) } \\

\text{compute the ratio} & \\
\frac { p \left( m _ { i } | z _ { 1 : t } , x _ { 1 : t } \right) } { p \left( \neg m _ { i } | z _ { 1 : t } , x _ { 1 : t } \right) } & = \frac { p \left( m _ { i } | z _ { t } , x _ { t } \right) } { 1 - p \left( m _ { i } | z _ { t } , x _ { t } \right) } \frac { p \left( m _ { i } | z _ { 1 : t - 1 } , x _ { 1 : t - 1 } \right) } { 1 - p \left( m _ { i } | z _ { 1 : t - 1 } , x _ { 1 : t - 1 } \right) } \frac { 1 - p \left( m _ { i } \right) } { p \left( m _ { i } \right) } \\
&\\
\text{Use log odd} & \\
l \left( m _ { i } | z _ { 1 : t } , x _ { 1 : t } \right) & = l \left( m _ { i } | z _ { t } , x _ { t } \right) + l \left( m _ { i } | z _ { 1 : t - 1 } , x _ { 1 : t - 1 } \right) - l \left( m _ { i } \right)

\end{aligned}
$$



### 6.2

$$
\begin{aligned} 
\alpha = 0.55 & \quad \beta = 0.4\\

\left( \frac { 0.55 } { 0.45 } \right) ^ { 0.6n } \times \left( \frac { 0.4 } { 0.6 } \right) ^ { 0.4n } &= \left( \frac { 11 } { 9 } \right) ^ { 600 } \times \left( \frac { 2 } { 3 } \right) ^ { 400 } \\

log\left( \left(\frac { 11 } { 9 } \right) ^ { 600 } \times \left( \frac { 2 } { 3 } \right) ^ {400} \right) &= 600log(\frac { 11 } { 9 }) + 400log(\frac { 2 } { 3 }) < 0


\end{aligned}
$$



The occupancy grid value converges to 0. And the reflection value is 0.4



### 6.3

 

![1557674676057](C:\Users\26996\AppData\Roaming\Typora\typora-user-images\1557674676057.png)



## Problem 7

### 7.1

- Assume that $p(x|r_{2}) < p_{max}​$ for all x

- Sample point x = [a, b] from a uniform distribution $U(X, Y) , X \in [x_{m2} - 2r_2, x_{m2} + 2r_2], Y \in [0, y_{m2} + 2r_2]$  in the gragh

- Sample c from [0, $p_{max}​$]

- if $p(x| r_2) > c$ then keep the sample [a, b]
  otherwise  reject the sample.



### 7.2

For each landmark j (j = 1, 3) calculate the distance between the robot and landmark m~j~, then use it to calculate the probability.
$$
{ \hat { r } = \sqrt { \left( m _ { j , x } - x \right) ^ { 2 } + \left( m _ { j , y } - y \right) ^ { 2 } } } \\
q = \operatorname { prob } \left( r _ { j } - \hat { r } , \sigma _ { r } \right) \\
$$
Multiply all probability of one sample position, use the probability as the weight  of the position x.

At last, need to normlize the weight.

### 7.3

$w_{t}$ is weight list, $M$ is the sample number, $ \overline{ \mathcal { X }  _ { t }}$ is new sample list.

Here is the one resampling step :
$$
\begin{array} { l } { \overline { \mathcal { X } } _ { t } = \emptyset } \\
{ r = \operatorname { rand } \left( 0 ; M ^ { - 1 } \right) } \\ { c = w _ { t } ^ { [ 1 ] } } \\ { i = 1 } \\
{\text {for } m = 1 \text { to } M \text{ do }} \\
{ \quad U = r + ( m - 1 ) \cdot M ^ { - 1 } } \\
{ \quad \text {while } U > c } \\ 
{ \quad\quad i = i + 1 } \\
{ \quad\quad c = c + u } \\
{ \quad \text {endwhile }} \\
{ \quad \text {add } x _ { t } ^ { [ i ] } \text { to } \overline { \mathcal { X } } _ { t } } \\
{\text{endfor}} \\
\end{array}
$$

## Problem 8

Because the world is full of uncertainty. To begin with, the environment are inherently unpredictable. Using uncertainty distribution can model the real world well.  Furthermore, sensors in the robot are limited in what they can perceive. Limitations arise from several factors. The range and resolution of a sensor is subject to physical limitations. What's more, the action of the robot is unpredicted. Uncertainty arises from effects like control noise, wear-and-tear, and mechanical failure.

We can see that there are many uncertainties in the feild of robotics, so it's not hard to understand that probabilistic models and reasoning techniques are preferred.